{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ef42ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce11ab",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product from www.amazon.in. The\n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "guitars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c03eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product to search on Amazon: mobile\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "search=driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "\n",
    "product_name = input(\"Enter the product to search on Amazon: \")\n",
    "search.send_keys(product_name)\n",
    "\n",
    "search_button = driver.find_element(By.ID, \"nav-search-submit-button\")\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623afcac",
   "metadata": {},
   "source": [
    "In the above question, now scrape the following details of each product listed in first 3 pages of your search\n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then\n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0dde1b",
   "metadata": {},
   "source": [
    "Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa100101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URLs have been saved to google_images_scrape.csv\n"
     ]
    }
   ],
   "source": [
    "keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "all_images = []\n",
    "\n",
    "image_urls = []\n",
    "\n",
    "for keyword in keywords:\n",
    "   \n",
    "    driver.get(\"https://images.google.com\")\n",
    "\n",
    "\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea\")\n",
    "    search.send_keys(keyword)\n",
    "    search.send_keys(Keys.RETURN)\n",
    "    \n",
    "images = driver.find_elements(By.CSS_SELECTOR, 'img.Q4LuWd')\n",
    "    \n",
    "for img in images:\n",
    "        \n",
    "            img_url = img.get_attribute('src') or img.get_attribute('data-src')\n",
    "            if img_url and len(image_urls) < 10: \n",
    "                image_urls.append(img_url)\n",
    "        \n",
    "\n",
    "for url in image_urls:\n",
    "        all_images.append({'Keyword': keyword, 'Image URL': url})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "        \n",
    "df = pd.DataFrame(all_images)\n",
    "\n",
    "df.to_csv('google_images_scrape.csv', index=False)\n",
    "print(\"Image URLs have been saved to google_images_scrape.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6babfcb",
   "metadata": {},
   "source": [
    "4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04558630",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964debb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
